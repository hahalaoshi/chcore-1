## Part1: Physical Page Management
Question:
Make a brief explanation: In which file or code segment specifies the CHcore physical memory layout. You can answer this question in two aspects: the compilation phase and runtime phase?

Answer:
In compilation phase buddy_struct.h specifies the physical memory layout.
It includes the definition of pages and also start/end address in the memory stack.
In runtime phase, mm_init function and more importantly init_buddy specify the layout.
mm_init determines the start address of metadata and init_buddy initializes metadata and pages.

Exercise1:
Implementation of buddy system:
Allocated page is marked 0 in the second bit of the flag, and free page is marked 1.
Both allocated page and free page have an order(in the head of the page).
The remaining part of the big page(continuous 0-order pages) is marked nothing.

`buddy_free_pages()` First check whether the `PG_buddy` flag is set. If it's head of a free page, just return.
I assume that all `page` passed here is the head of the big page.(Otherwise, `first_page` field can be set to implement this but I don't think it's a good design.)
And then check whether the buddy can be merged. Keep merging until it's too big(bigger than max order page) or buddy cannt be merged anymore.
`buddy_get_pages()` I didn't follow the hint which suggest to check whether the return page has an invalid order.
The result of `__alloc_page()` would be null if the order is invalid so I can directly return the result.
`__alloc_page()` Check whether the corresponding order freelist has a free page. If it doesnt try to split a high order page. And then get the page and set the order.

## Part 2: Virtual Memory
Question:
Assuming that the following CHcore kernel code is correct, which type should variable x have, vaddr_t or paddr_t?

Answer:
The type of x should be vaddr_t.
mystery_t is converted from char *(T *, as is refered to in the document)
which can only be virtual address type.

Question:
1. How much space overhead is there for managing memory, if we actually had the 4G physical memory? How is this overhead broken down?
2. Summarize the difference between X86 and ARM address translation mechanisms, what is the advantage of arm-smmu architecture design?

Answer:
1. page metadata size + page table size(maximum): 40MB + 8MB = 48 MB (approximately)
   number of pages: 4G/4K= 2^20, size of struct page is 40B, so the overhead of pages metadata is 40B * 2^20 = 40MB.
   each table level has 512 entries, but to map 2^20 pages,
   we only need 2^11 L3 page tables, 2 L2 page table, 1 L1 page table, 1 L0 page table
   so the maximum size of page table is (2^11+2+1+1)*4K=8M(approximately)

   The overhead can be broken down by dynamically allocate and free pages. Initially only one L0 table is needed.
   Multiple level page tables help reduce the overhead of unnecessary succeeding page tables.
   Try to use continuous virtual memory which can raise the utilization of page tables.
   Free the pages and page tables when they are not needed anymore.
2. arm has two TTBR and x86 only has one. Kernel memory is mapped to higher address in x86 but arm use a different page table to access kernel memory.
x86 supports both segmentation and paging. arm-smmu supports 2-stage translation. arm-smmu is simpler and has better isolation.

Exercise2:
In the file kernel/arch/aarch64/mm/page_table.c, you must implement code for the following functions.
`map_range_in_pgtbl()` Use a loop to do the mapping in page granularity. Invoke `get_next_ptp` to create next level page table page and then set the page table entry.
`unmap_range_in_pgtbl()` Get the page table entry with `get_next_ptp`. And `memset` the entry to 0.
`query_in_pgtbl()` Get the entry and the pfn.

## Part 3: Kernel Address Space
Question:
1. Why CHcore organize the kernel page table in block entry? Which range of virtual address space must map in the boot time and which can delay until the kernel starts?
2. Why will user programs not be able to read or write the kernel's memory? What specific mechanisms protect the kernel memory?

Answer:
1. Kernel memory is too large for page granularity mapping. Block entry helps reduce page table access times. And also kernel memory are accessed more frequently so it's better to store a large part of it in tlb and cache.
 [KBASE, KBASE + 128M) needs to be mapped in boot time because it helps start the kernel and build the page table. Other parts based on kernel memory accessing or that do change to page table can be delayed, for example device memory, process memory and some kernel services.
2. Because user programs are not trusted and they should be isolated from each other and from the kernel. Their access to kernel memory may cause inconsistency or change permissions and also influence other user programs.
Kernel memory is mapped in other page tables with a different TTBR. And also some bits in page table entry mark the address as user-invisible.

Exercise 3:
Fill in the missing code in map_kernel_space(). Your code should now pass the kernel_space_check()
`map_kernel_space()` Kernel page table page is already there so only need to get the entry and then set the memory attributes.

Challenge 1. Map the kernel space in the page granularity. In default, only user process can map virtual address in the page  granularity, so you need to  modify the function set_pte_flags().
The code is written in `map_kernel_space()` and has been commented. Set the flag as kernel mapping and invoke `map_range_in_pgtbl` to map in page granularity.
`set_pte_flags()` has been changed to support kernel mapping and block mapping. For kernel mapping, user can't read, write or execute the code.

Challenge 2. Support hugepage / block for Chcore, you should modify the map_range_in_pgtbl() in page_table.c and set the page attribution bit carefully.
`map_range_in_pgtbl()`, `set_pte_flags()` and `unmap_range_in_pgtbl()` have been changed to support mapping in block granularity.
Two new bits are added in flags to stand for L1_BLOCK and L2_BLOCK. In `map_range_in_pgtbl()`, check the flag to determine the granularity of mapping.
Set the memory attribute after ptp is created. Originally `set_pte_flags` is only for page mapping. Now it will check the flag and set the corresponding bits based on it's page or block.
The test is added to `test_aarch64_page_table.c` but has been commented. Uncomment line 224 to test block mapping.
