## ChCore Lab 4: Multiprocessing
517021910851-于亚杰
### Part A: Multiprocessor Support
> **Question 1**: Read the assembly code `_start` in `boot/start.S`
Use `git diff lab3` to compare the difference of `_start` between previous labs and Lab4.
Explain how `_start` determines the BSP and blocks the APs.

The forever hanging part is removed. For secondary cpus, they are first initialized and then blocked and then continue to boot.
`cbz x8, primary` separate cpu 0 from others and thus it's BSP and boot first. 
Stacks of APs are initialized until the instruction `cbz     x3, hang`. It will check the corresponding secondary boot flag to determine whether it could continue to boot. If it's not allowed to continue yet, it's blocked.
The flag is set by BSP.

> **Exercise 2**: There is a newly added function `enable_smp_cores()` in `main()`. 
> Read the code of `enable_smp_cores()` in `kernel/common/smp.c` and the assembly `code _start`
> in `boot/start.S`.  Fill the C code in `enable_smp_cores()` and `secondary_start()` of 
> `kernel/main.c`, so that the BSP activates the APs one by one. 
> You should pass test smp and get the first 5 points!

`(long *)secondary_boot_flag + i` is the flag for cpu `i`. Set the flag to 1 and wait until its status to be `cpu_run`. In `secondary_start` set the `cpu_status` to `cpu_run`.

> Question 3: Make sure you understand the control flow of booting APs, 
> which is much like the BSP's. Please answer the question that 
> is it correct for the BSP to activate the APs simultaneously instead of one by one? 
> In other words, will simultaneously booting APs cause concurrent problems?
> Hints: Check whether each CPU shares the same kernel stack.
> Hints: Check whether each function call in the control flow can cause race conditions.

No, it's not correct to activate simultaneously. It seems like they share different kernel stack shown in `head.S` and also different boot cpu stack shown in `start.S`.
There could be race conditions since the two processors can run kernel code at the same time. 
Such as `print` being called concurrently would mess the output. Also `sched()`, enabling and disabling of `irq` may not be executed concurrently too.

> **Exercise 4**: Get familiar with the basic idea of the ticket lock. Then fill the blank the `unlock()` and `is_locked()` in `kernel/common/lock.c`.
> Attention: there is no need to use any assembly code such as the memory barrier 
> and the code you need to write is less than five lines. 
> Your code should pass test mutex and get 5 points! 

It's a little bit tricky since I can only think of two lines to be added.

> **Exercise 5**: Implement the `kernel_lock_init()`, `lock_kernel()`, 
> and `unlock_kernel()` in `kernel/common/lock.c`. 
> Apply the big kernel lock as described above, by calling `lock_kernel()` and `unlock_kernel()` at the proper locations. 
> Your code should pass test big lock and get 5 points!.

Invoke the lock operations with `big_kernel_lock` as the parameter in kernel lock operations. 
Use `type` in `handle_irq` and `handle_entry_c` to determine the exception level.
`bl unlock_kernel` to unlock big kernel lock in assembly.


> **Question 6**: When calling unlock_kernel() in exception_return,
> you do not need to save the values of registers such as x0 to the stack,
> which is done when el0_syscall calls lock_kernel(). Why?

When calling `lock_kernel` in `el0_syscall`, the exception level doesnt change and registers still need to be used in later codes.
While in `exception_return`, no old register's value is used in `exception_exit` so they don't need to be saved. 
And after `exception_exit`, the exception level is changed from kernel to user, which have different state of registers.
So the point is the value of registers before unlock in `exception_return` is useless.

### Part B: Scheduling
> **Exercise 7**: Implement the functions in `kernel/sched/policy_rr.c`. 
> Your code should pass test cooperative and get 10 points!. 
> Now, your scheduler can work on one CPU.

+ `rr_sched_enqueue`: append the thread to the ready queue; set state to ready.
+ `rr_sched_dequeue`: delete from ready queue; set state to intermediate.
+ `rr_sched_choose_thread`: choose from ready queue and remove it; or set it to idle; set the state to running.
+ `rr_sched`: enqueue current thread; choose a thread to run; set budget of the thread; switch to thread.
+ `rr_sched_handle_timer_irq`: just call `rr_sched`.

> **Exercise 8**: Remind that you have acquired the big kernel lock in `handle_irq` of `kernel/exception/irq.c`
> if the exception is from the user mode. However, there is a special case that if the exception is caught in the idle 
> threads (which run in the kernel mode), where you should also acquire the big kernel lock. There is no test for this exercise, but you have to finish it.
> Otherwise, your kernel may block forever. Please think of the reason.

When an idle thread is run in kernel mode, it will have no chance to give back the kernel lock. And the thread routine of idle thread is just hanging there forever.
So we should prevent idle thread from running by acquiring the kernel lock and the cpu is able to do the rescheduing.

> **Exercise 9**: Now, although your scheduler is not complete, it is ready to run some simple user-mode programs.
> Implement syscall `sys_get_cpu_id()` in `syscall.c`, which tells the user-mode program the id of the CPU it is running on.
> Implement syscall `sys_yield()` in `sched.c` which enables the user-mode program to initiate a thread scheduling.
> You should be able to run `yield_single.bin`.

+ `sys_get_cpu_id()` return `smp_get_cpu_id()`.
+ `sys_yield` reschedule and use eret to switch the context and run the target thread.

> **Exercise 10**: Uncomment the code `timer_init()` in `exception_init_per_cpu()`.
> This will enable the hardware timer interrupt in user mode. 
> Then you should also modify `handle_irq()` of `kernel/exception/irq.c` to make the interrupt handling can run normally.
> You should be able to get the `/yield_spin.bin` test to work: the main thread should be able to regain the control of the
> CPU after a certain time and terminate gracefully. Because of the test scripts, you can not run `make grade` to get the 5 points of test `yield spin`,
> and they will be given back later.

In `handle_irq`, when interrupt is handled, kernel would reschedule and switch the context. So `sched_handle_timer_irq()` is called here and then do the rescheduling.

> **Exercise 11**: Modify your scheduler logic in `kernel/sched/policy_rr.c` so that it can support budget.
> Follow the above description, implement `rr_sched_handle_timer_irq()`. 
> Do not forget to call `sched_handle_timer_irq()` in a proper code location.
> Do not to forget to reset the budget in `sys_yield()` in `kernel/sched/sched.c`,
> so that it can still schedule out the current thread immediately. Your code should pass test preemptive and get 5 points!

The timer handler is only responsible for decreasing the budget. In `sched()`, check whether the budget equals zero and do the reschedule. 
I think the *proper code location* is in `irq.c` and done in the last exercise.

> **Exercise 12**: Enable your `rr_sched_enqueue()` in `kernel/sched/policy_rr.c` to act depends on the enqueued thread's affinity.
> If the affinity is not set to `NO_AFF`, you should enqueue the thread to the `rr_ready_queue` of the current CPU.
> Otherwise, enqueue the thread to the `rr_ready_queue` specified by affinity. Your code should pass test affinity and get 5 points! 
> Up to now, you can run the comprehensive test sched for your scheduler.
> You should pass test sched and get 5 points! Then, you have passed all the Lab 4 kernel tests.
> Run make grade, you should pass tests `yield single`, `yield spin`, and `yield multi`, and get 15 points!

The main challenge here is to check the type and status of thread. One situation is that when `sys_exit` is called, the current thread is set to null.
That also means it's removed from the ready queue. And when affinity is set to the context, `cpuid` also needs to be set.

> **Exercise 13**: Implement syscall `sys_set_affinity` and `sys_get_affinity` in `thread.c`.
> You should pass tests `yield aff` and `yield mutli aff`, and get 10 points!

Just set the affinity and get the affinity in thread context. One point to mention here is that thread could be null when trying to set or get its aff.
This usually happens when the thread has exited, so the function has to return in this case instead of `obj_put` a null pointer. 

### Part C: Spawn
> **Exercise 14**:  Implement `spawn()` in `user/lib/spawn.c`.
> You should pass test `spawn basic`, and get 10 points!
> Attention: you are not required to do large amounts of coding,
> just replace all the `LAB4_SPAWN_BLANK` with correct expression.

Follow the lab guidance and I can easily determine the correct values for the blank. 
Stack top includes the `argc` and `argv` but stack offset just refers to stack pointer which is under `argv`.

> **Exercise 15**:  Implement `spawn()` in `user/lib/spawn.c`.
> You should pass test `spawn info`, and get 5 points!.
> Attention: you are not required to do large amounts of coding;
> the total number of code should be no more than 20 lines.

The only confusing part is in `syscall.c` where the same parameters of `usys_transfer_caps` and `usys_map_pmos` have different names.
The guidance has very detailed information about how to write the code.

### Part D: Inter-Process Communication (IPC)
> **Exercise 16**: We have provided you with most code of IPC related syscalls in `kernel/ipc/`.
> Please fill the rest according to the comments in the file. You should pass tests `ipc data` and `ipc mem`, and get 15 points!.
Attention: you are not required to do large amounts of coding, just replace all the LAB4_IPC_BLANK with correct expression.

The vmspaces in server and client are different but have a fixed difference, which will be added when `ipc_msg` is transferred as argument. 
Most blanks are easy but it's important to set target thread stack correctly because it doesn't matter in the first test but matters in the second one.
And the description is a little bit confusing since just replace all the blanks cannt pass the test. 
After some debugging I figure out the caps are not transferred from client to server so `ipc_sendcap_cap` needs to be called.

> **Exercise 17**: Be sure you have understood the workflow of IPC.
> In the last exercise, you need to implement a simplified syscall called
> `sys_ipc_reg_call()`, which is much similar to `sys_ipc_call()`. The only difference is that the
> second argument of `sys_ipc_reg_call()` is a 64-bit value instead of the address to the shared memory buffer.
> The second argument should be transferred to the server thread directly, as the only parameter of ipc_dispatcher().
> You should pass test ipc reg, and get 5 points!

No `ipc_msg` so no caps need to be transferred. And also the argument is not a pointer so dont need to consider the change of vmspace.
Just remove the unnecessary part of the origin `sys_ipc_call`.

### Bonus
The send and recv function are defined in these two file.
+ `u64 sys_ipc_send(u32 conn_cap, u64 msg)`: `kernel/ipc/ipc_send.c`
+ `u64 sys_ipc_recv()`: `kernel/ipc/ipc_recv.c`

The `sys_ipc_send` will send a `u64` number to the receiver if the receiver is blocking(ready to receive).
Or if the receiver is not ready, it will just return 0, which means the send function did nothing and the message is abandoned.
So send function will never block.

The `sys_ipc_recv` will block until it gets a message. 

I used shared buf in the connection to pass the message. The detailed implementation can be seen in the code with comments.
There are two major points to mention. First is that the syscall is not allowed to block since it's acquired a kernel lock, 
so in receive function I have to release the lock in the beginning and reacquire the lock before returning.
Second is that volatile should be used for the shared address in order to avoid optimization of assembler.

Some other files are modified but not really important. Syscalls are added and also in `create_connection` I change the target thread
from new created thread to the receiver.

Test programs are `user/lab4/ipc_recv_server.c` and `user/lab4/ipc_send_client.c`.
The first register part is similar to the `ipc_reg.c`. Send client will repeatedly send message to the server and record the send times.
And the receiver will receive once and try to block.
Finally from the output we can see the sender send many times and the receiver gets the correct message.

Results are like this.
```shell script
$ sudo make user
$ sudo make run-ipc_send_client

[Sender] send message 1100, send times: 11 
[Sender] exit
[Receiver] receive message: 1100
[Receiver] exit

$ sudo make run-ipc_send_client
[Sender] send message 1000, send times: 10 
[Sender] exit
[Receiver] receive message: 1000
[Receiver] exit
```
